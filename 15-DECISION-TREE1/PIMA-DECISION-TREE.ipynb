{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.read_csv('pima_indians_diabetes_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['preg_count', 'glucose_concentration', 'diastolic_bp',\n",
       "       'triceps_skin_fold_thickness', 'two_hr_serum_insulin', 'bmi',\n",
       "       'diabetes_pedi', 'age', 'diabetes_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pima[['preg_count', 'glucose_concentration', 'diastolic_bp',\n",
    "       'triceps_skin_fold_thickness', 'two_hr_serum_insulin', 'bmi',\n",
    "       'diabetes_pedi', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg_count</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>triceps_skin_fold_thickness</th>\n",
       "      <th>two_hr_serum_insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetes_pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     preg_count  glucose_concentration  diastolic_bp  \\\n",
       "0             6                    148            72   \n",
       "1             1                     85            66   \n",
       "2             8                    183            64   \n",
       "3             1                     89            66   \n",
       "4             0                    137            40   \n",
       "..          ...                    ...           ...   \n",
       "763          10                    101            76   \n",
       "764           2                    122            70   \n",
       "765           5                    121            72   \n",
       "766           1                    126            60   \n",
       "767           1                     93            70   \n",
       "\n",
       "     triceps_skin_fold_thickness  two_hr_serum_insulin   bmi  diabetes_pedi  \\\n",
       "0                             35                     0  33.6          0.627   \n",
       "1                             29                     0  26.6          0.351   \n",
       "2                              0                     0  23.3          0.672   \n",
       "3                             23                    94  28.1          0.167   \n",
       "4                             35                   168  43.1          2.288   \n",
       "..                           ...                   ...   ...            ...   \n",
       "763                           48                   180  32.9          0.171   \n",
       "764                           27                     0  36.8          0.340   \n",
       "765                           23                   112  26.2          0.245   \n",
       "766                            0                     0  30.1          0.349   \n",
       "767                           31                     0  30.4          0.315   \n",
       "\n",
       "     age  \n",
       "0     50  \n",
       "1     31  \n",
       "2     32  \n",
       "3     21  \n",
       "4     33  \n",
       "..   ...  \n",
       "763   63  \n",
       "764   27  \n",
       "765   30  \n",
       "766   47  \n",
       "767   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pima[['diabetes_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7012987012987013\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77       146\n",
      "           1       0.61      0.52      0.56        85\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.68      0.66      0.67       231\n",
      "weighted avg       0.69      0.70      0.70       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  In the above the precision recall should be highter and the support should be eequal for both 0 , 1 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = DecisionTreeClassifier(criterion = \"entropy\", splitter = \"random\", max_depth = 20,  min_samples_split = 8,min_samples_leaf = 2, max_features = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=20, max_features=2, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=8,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='random')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8484848484848485\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89       146\n",
      "           1       0.85      0.72      0.78        85\n",
      "\n",
      "    accuracy                           0.85       231\n",
      "   macro avg       0.85      0.82      0.83       231\n",
      "weighted avg       0.85      0.85      0.85       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(metrics.classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "criterion: This parameter determines how the impurity of a split will be measured. \n",
    "    The default value is “gini” but you can also use “entropy” as a metric for impurity."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "splitter: This is how the decision tree searches the features for a split.\n",
    "    The default value is set to “best”. That is, for each node, the algorithm considers all \n",
    "    the features and chooses the best split. If you decide to set the splitter parameter to “random,” \n",
    "    then a random subset of features will be considered. The split will then be made by the best feature within the random subset. The size of the random subset is determined by the max_features parameter. \n",
    "    This is partly where a Random Forest gets its name."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max_depth: This determines the maximum depth of the tree. In our case, we use a depth of two to make our decision tree.\n",
    "    The default value is set to none. This will often result in over-fitted decision trees. The depth parameter is one\n",
    "    of the ways in which we can regularize the tree, \n",
    "    or limit the way it grows to prevent over-fitting."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "min_samples_split: The minimum number of samples a node must contain to consider splitting.\n",
    "    The default value is two. You can use this parameter to regularize your tree."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "min_samples_leaf: The minimum number of samples needed to be considered a leaf node. \n",
    "    The default value is set to one. Use this parameter to limit the growth of the tree."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max_features: The number of features to consider when looking for the best split. \n",
    "    If this value is not set, the decision tree will consider all features available to make the best split. \n",
    "    Depending on your application, it’s often a good idea to tune this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score:  0.6629331184528606\n",
      "f1 score:  0.5605095541401275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score,f1_score\n",
    "print(\"roc_auc_score: \", roc_auc_score(y_test, y_pred))\n",
    "print(\"f1 score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the ‘roc_auc_score’ and the ‘f1_score.’ The ‘roc_auc_score’ is\n",
    "the area under the receiving operating characteristic curve. It is a measure of how well the \n",
    "binary classification model can distinguish classes. A ‘roc_auc_score’ of 0.5 means the model\n",
    "is unable to distinguish between classes. Values close to 1.0 correspond to a strong separation between classes. The ‘f1_score’ is the harmonic mean of precision and recall.\n",
    "Similar to ‘roc_auc_score’, a perfect ‘f1_score’ is equal to 1.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/building-classification-models-with-sklearn-6a8fd107f0c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DOT data\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                                feature_names=iris.feature_names,  \n",
    "                                class_names=iris.target_names)\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
